Important Note: This exercise is inspired by Ruslan's "Let's Build A Web Server" series as a kind of follow up. As we will be using online resources to help, please read the reference section at the end first before beginning the exercise.

(Easy to Medium+ depending on how serious you get)
0. First we want to refine some aspect of the codes in the blog series to make further development on top of them more pleasant to work with.

a) You may come across problem when trying to test part 1 using telnet in window. It turns out that telnet may decide to send packets as it receives characters you type, rather than sending them all at once. Since the function client_connection.recv(1024) means trying to get "something" with an upper bound of fetching 1024 bytes at most, you may get cut off after entering a single character. What we really need is some sort of protocol coupled with a stream interface - we should be persistantly reading until we know enough about the beginning part of the content sent to know the actual length of the whole payload - in this case it is the 'Content-Length' http header field that will tell us.

Extract suitable function from part 2's code to help with parsing the packet's content, and then write a code snippet to properly read the packet and insert it into the code in part 1. (Hint: use the readline and read function)

b) Add logging to the code in part 1 and part 2 so that we can debug more easily. After importing logging, add the line
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format='%(asctime)s [%(levelname)s] %(message)s')
for a minimal setup, then add log in places you think are important.

c) The code in part 2 skipped some details of the WSGI requirement to simplify things, and we need to add some of that back in.
i. The 'PATH_INFO' parameter is currently the whole path. Write functions to extract query string into 'QUERY_STRING' and correct the line for 'PATH_INFO' correspondingly.
ii. Write functions to extract all http headers and add them to the environ dict in one stroke. (Be careful about special case of 'CONTENT_LENGTH')

(Optional) d) Study using multiprocessing to make a httpd daemon so that starting/stopping server is less tedious.


1. A Web Framework provides its own model of how things work, as well as a more convenient and/or more powerful interface to the user than the actual interface to the web server (which in this case is the WSGI). They achieve this by layering on top of the basic interface, doing some of the tasks that can be generalized. We will build a heavily simplified micro web framework incrementally, starting with miscellaneous functions.

a) The first issue is that the data structure in WSGI is too low-level with everything packed in one single env dict - we want to present the data in a cleaner way that is also more meaningful from a user's point of view.

Let's create a class named HttpReq (Shortform for HTTP Request) that is just data structure:

class HttpReq:
	pass

It should have the following attributes:
url: The URL being requested.
method: 'GET' or 'POST'
headers: a python dict whose keys are the header names and the values are the corresponding header values.
getparams: if request method is 'GET', this should be a python dict of the request parameters whose keys are parameter names and the values are the corresponding parameter values. The value should be a python array if there is a repeat of parameter name.
postparams: if request method is 'POST', this should be a python dict with the request parameters in the same schema as getparams.

(i) Write a helper function extractHeaders(env) to extract headers from the env dict according to the requirement for the class HttpReq.
(ii) Write a function get_req(env) to construct and return a HttpReq object from the env dict, conforming to the above specification.
Note: You are allowed to use the module urlparse (urllib.parse if using Python 3) in standard library for this question.

b) The second and third (and fourth) issues are that it is still too cumbersome to work directly with HTTP request and response (too much boilerplate code to extract data from request object manually as well as assembly/building response object), and for larger projects with many 'pages' located at various URL, doing everything in one function is confusing and difficult to manage (try searching through/jumping around the code!). Different frameworks may use different mechanisms, but some common ideas are:
- Use handler that focus on dealing with requests on one particular (or one family of) resource.
- Inject various kinds of parameters into the handler, and only require the handler to return the core content of the response (or return an abstracted response object)
- Some frameworks will also allow automatic configuration of the web application itselfs to varying degree.

In this exercise, we will implement a 'router' in the framework (explained in question 2 below), use dependency injection-like method to provide the parameters, and use decorator for auto-config (a similar thing is called annotation-driven config in Java).

Implement a decorator called 'route' that is applied to methods (which is a kind of callable in python) acting as handler. The decorator should have the following arguments:
url (mandatory): for which URL will this handler be able to process the request?
method (optional): any restriction on request type? 'GET' if handler only deals with GET request, 'POST' for 'POST' request only, and 'ANY' for no restriction. Defaults to 'ANY'.

It should wrap the method and apply dependency injection by inspecting the method argument names and providing the corresponding request parameters (using None as value if it doesn't exist).

As an example:

class TodoApp:
	@route('/todo/create', method='POST')
	def addTodoListItem(self, task, pos):
		# ...snip...

Here the route's URL is '/todo/create', the method is 'POST', and the decorator should extract request parameters 'task' and 'pos' if they exists.


Reference:

The original tutorial/DIY series is at https://ruslanspivak.com/lsbaws-part1/ (Part 1, follow links at bottom to get to other parts), and we assume that the reader has already read (but not neccessarily worked out) both part 1 and part 2 throughout this exercise.

We will be working and perhaps tinklering with both HTTP's protocol detail and drill down on WSGI's interface a bit. For http, the authoritative reference is the original spec at https://www.w3.org/Protocols/rfc2616/rfc2616-sec4.html#sec4 .

Python's standard socket library provide a function socket.makefile to allow accessing socket through a file-like api. However there are some subtlety involved and it have (previously?) some limitations. Nonetheless it is good enough for our exercise. See http://stackoverflow.com/questions/12203800/should-i-close-makefileed-socket-and-it-is-original-socket-independently for hints on how to use it.

One of Python's strength has been in its battery included philosophy while providing an easy, accessible interface and supporting a wide variety of system integration tasks. Logging is taken care of in a similar spirit and it is in fact a built in library. Read https://docs.python.org/2/howto/logging.html#logging-basic-tutorial for an introduction.

It turns out that you cannot test the simple server in part 2 with chrome because of speculative connection that send nothing, see http://stackoverflow.com/questions/4761913/server-socket-receives-2-http-requests-when-i-send-from-chrome-and-receives-one for explanation.

WSGI is an old school interface that still works - similar to the CGI interface at the dawn of web 2.0 one or two decades before. Refer to https://wsgi.readthedocs.io/en/latest/definitions.html for a brief description of the environ keys, and read http://wsgi.tutorial.codepoint.net/ to quickily learn how to work with it practically.

